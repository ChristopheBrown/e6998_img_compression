{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, logging\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Input\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "logging.disable(logging.WARNING) \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.2.0\n",
      "Is GPU available? [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Eager execution on? True\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n",
    "print(\"Is GPU available? {}\".format(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Eager execution on? {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Layer Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is to perform the rnn_conv operation that makes up the building block of the encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_conv_channels = 32\n",
    "\n",
    "D_conv1_channels = 512\n",
    "D_rnn1_channels = 512\n",
    "D_rnn2_channels = 512\n",
    "D_rnn3_channels = 256\n",
    "D_rnn4_channels = 128\n",
    "D_conv2_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.normal(size=(128,32,32,3))\n",
    "ENCODER_DIM = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Class Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnConv(Layer):\n",
    "    \n",
    "    def __init__(self, filters, kernel_size, strides, index, batch_size):\n",
    "        \n",
    "        super(RnnConv, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.index = index        \n",
    "        self.hidden, self.cell = self.init_hiddens(filters)\n",
    "        \n",
    "        self.conv_inputs_layers = Conv2D(filters=filters, kernel_size=4*kernel_size, strides=strides, padding=\"same\", trainable=True)\n",
    "        self.conv_hidden_layers = Conv2D(filters=filters, kernel_size=4*kernel_size, padding=\"same\", trainable=True)\n",
    "        \n",
    "        self.in_gate = Dense(filters, activation=\"sigmoid\", dtype='float64', trainable=True)\n",
    "        self.f_gate = Dense(filters, activation=\"sigmoid\", dtype='float64', trainable=True)\n",
    "        self.out_gate = Dense(filters, activation=\"sigmoid\", dtype='float64', trainable=True)\n",
    "        self.c_gate = Dense(filters, activation=\"tanh\", dtype='float64', trainable=True)\n",
    "        \n",
    "        self.hidden_weight = Dense(1, activation=\"tanh\", dtype='float64', trainable=True)\n",
    "\n",
    "    def init_hiddens(self, num_filters):\n",
    "\n",
    "        h_w_scale_factor = 2**(self.index+1)\n",
    "        h_w = int(32 // h_w_scale_factor) #32 is the input dims, decreasing by factor of 2 for each layer\n",
    "\n",
    "        shape = [self.batch_size] + [h_w, h_w] + [num_filters]\n",
    "        hidden = tf.zeros(shape, dtype='float64')\n",
    "        cell = tf.zeros(shape, dtype='float64')\n",
    "\n",
    "        return (hidden, cell)\n",
    "    \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        self.batch_size = inputs.shape[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_inputs = self.conv_inputs_layers(tf.Variable(inputs))\n",
    "        self.conv_hidden = self.conv_hidden_layers(self.hidden)\n",
    "\n",
    "        in_gate, f_gate, out_gate, c_gate = tf.split(self.conv_inputs + self.conv_hidden, 4, axis=-1)\n",
    "         \n",
    "        in_gate_output = self.in_gate(in_gate)\n",
    "        f_gate_output = self.f_gate(f_gate)\n",
    "        out_gate_output = self.out_gate(out_gate)\n",
    "        c_gate_output = self.c_gate(c_gate)\n",
    "        \n",
    "        new_cell = tf.math.add(tf.multiply(f_gate_output, self.cell), tf.multiply(in_gate_output, c_gate_output))\n",
    "        new_hidden = tf.multiply(out_gate_output, self.hidden_weight(new_cell))\n",
    "        \n",
    "        for old_state, new_state in zip(tf.nest.flatten(self.cell), tf.nest.flatten(new_cell)):\n",
    "            old_state = new_state\n",
    "            \n",
    "        for old_hidden, new_hidden in zip(tf.nest.flatten(self.hidden), tf.nest.flatten(new_hidden)):\n",
    "            old_hidden = new_hidden        \n",
    "        \n",
    "        # self.cell = self.new_cell # should this update the state of the LSTM cell in this layer (and not propagate forward)\n",
    "        # self.hidden = self.new_hidden\n",
    "        \n",
    "        return (self.hidden, self.cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Layer):\n",
    "    \n",
    "    def __init__(self, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        write defintions of stuff here\n",
    "        \"\"\"\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # self.batch_size, self.height, self.width, self.channels = images.shape\n",
    "        self.E_conv_channels = 64\n",
    "        self.E_rnn1_channels = 256\n",
    "        self.E_rnn2_channels = 512\n",
    "        self.E_rnn3_channels = 512\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.input_conv = Conv2D(input_shape=(32,32,3), filters=self.E_conv_channels, kernel_size=3, activation = \"relu\", strides = (2,2), padding='same', dtype='float64', trainable=True)\n",
    "        self.hiddens1 = RnnConv(filters=self.E_rnn1_channels, kernel_size=3, strides=2, index=1, batch_size=self.batch_size)\n",
    "        self.hiddens2 = RnnConv(filters=self.E_rnn2_channels, kernel_size=3, strides=2, index=2, batch_size=self.batch_size)\n",
    "        self.hiddens3 = RnnConv(filters=self.E_rnn3_channels, kernel_size=3, strides=2, index=3, batch_size=self.batch_size)\n",
    "    \n",
    "    \n",
    "    def call(self, inputs):\n",
    "                        \n",
    "        self.input_conv_result = self.input_conv(inputs)\n",
    "                \n",
    "        self.hiddens1_output = self.hiddens1(self.input_conv_result)          \n",
    "        self.hiddens2_output = self.hiddens2(self.hiddens1_output[0])\n",
    "        self.hiddens3_output = self.hiddens3(self.hiddens2_output[0])\n",
    "                \n",
    "        return self.hiddens3_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binarizer(Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Binarizer, self).__init__()\n",
    "        \n",
    "        self.bin_input = Conv2D(input_shape=(2,2,512), filters=32, strides=1, kernel_size=1, activation=tf.nn.tanh, padding=\"same\", trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "    \n",
    "        bin_input_conv = self.bin_input(inputs)\n",
    "        probability = (bin_input_conv + 1) / 2\n",
    "        \n",
    "        # distribution = tfp.distributions.Bernoulli(probs=probability, dtype=tf.float32)\n",
    "        # noise = 2 * distribution.sample() - 1 - bin_input_conv\n",
    "        \n",
    "        bin_output = bin_input_conv # + tf.stop_gradient(noise)\n",
    "                \n",
    "        bits = tf.math.sign(bin_output)\n",
    "        \n",
    "        \n",
    "        return bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Layer):\n",
    "    \n",
    "    def __init__(self, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # self.batch_size, self.height, self.width, self.channels = images.shape\n",
    "        self.D_conv_channels = 512\n",
    "        self.D_rnn1_channels = 512\n",
    "        self.D_rnn2_channels = 256\n",
    "        self.D_rnn3_channels = 256\n",
    "        self.D_rnn4_channels = 128\n",
    "        \n",
    "        self.input_conv = Conv2D(input_shape=(2,2,32), filters=512, strides=1, kernel_size=1, activation=\"relu\", padding=\"same\", dtype='float64', trainable=True)\n",
    "        \n",
    "        self.lambda_layer1 = layers.Lambda(lambda x: tf.nn.depth_to_space(input=x, block_size=2, data_format=\"NHWC\"))\n",
    "        self.lambda_layer2 = layers.Lambda(lambda x: tf.nn.depth_to_space(input=x, block_size=2, data_format=\"NHWC\"))\n",
    "        self.lambda_layer3 = layers.Lambda(lambda x: tf.nn.depth_to_space(input=x, block_size=2, data_format=\"NHWC\"))\n",
    "        self.lambda_layer4 = layers.Lambda(lambda x: tf.nn.depth_to_space(input=x, block_size=2, data_format=\"NHWC\"))\n",
    "        \n",
    "        self.hiddens1 = RnnConv(filters=self.D_rnn1_channels, kernel_size=2, strides=1, index=3, batch_size=self.batch_size)\n",
    "        self.hiddens2 = RnnConv(filters=self.D_rnn2_channels, kernel_size=3, strides=1, index=2, batch_size=self.batch_size)\n",
    "        self.hiddens3 = RnnConv(filters=self.D_rnn3_channels, kernel_size=3, strides=1, index=1, batch_size=self.batch_size)\n",
    "        self.hiddens4 = RnnConv(filters=self.D_rnn4_channels, kernel_size=3, strides=1, index=0, batch_size=self.batch_size)\n",
    "                \n",
    "        self.output_conv = Conv2D(filters=3, strides=1, kernel_size=1, activation=\"relu\", padding=\"same\", trainable=True)\n",
    "    \n",
    "    \n",
    "    def call(self, binarizer_output):\n",
    "        \n",
    "        self.input_conv_result = self.input_conv(binarizer_output)\n",
    "                \n",
    "        self.hiddens1_output = self.hiddens1(self.input_conv_result) \n",
    "        self.depth_to_space1 = self.lambda_layer1(self.hiddens1_output[0])\n",
    "        \n",
    "        self.hiddens2_output = self.hiddens2(self.depth_to_space1) \n",
    "        self.depth_to_space2 = self.lambda_layer2(self.hiddens2_output[0])\n",
    "        \n",
    "        self.hiddens3_output = self.hiddens3(self.depth_to_space2) \n",
    "        self.depth_to_space3 = self.lambda_layer3(self.hiddens3_output[0])\n",
    "        \n",
    "        self.hiddens4_output = self.hiddens4(self.depth_to_space3) \n",
    "        self.depth_to_space4 = self.lambda_layer4(self.hiddens4_output[0])\n",
    "        \n",
    "        self.output_conv_results = self.output_conv(self.depth_to_space4)\n",
    "                \n",
    "        return self.output_conv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecompressionNetwork(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, batch_size):\n",
    "        super(DecompressionNetwork, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.encoder = Encoder(self.batch_size)\n",
    "        self.binarizer = Binarizer()\n",
    "        self.decoder = Decoder(self.batch_size)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        encoder_output = self.encoder(inputs)\n",
    "        bin_output = self.binarizer(encoder_output)\n",
    "        decoder_output = self.decoder(bin_output)\n",
    "        \n",
    "        # compute loss\n",
    "        im1 = tf.image.convert_image_dtype(inputs, tf.float64)\n",
    "        im2 = tf.image.convert_image_dtype(decoder_output, tf.float64)\n",
    "        \n",
    "        ssim_loss = tf.reduce_mean(tf.image.ssim(im1, im2, 2.0))\n",
    "        ssim_loss = tf.dtypes.cast(ssim_loss, tf.float64)\n",
    "        self.add_loss(ssim_loss)\n",
    "        \n",
    "        decoder_output = tf.Variable(decoder_output, dtype=tf.float64)\n",
    "        \n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "step 0: mean loss = 0.2757\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-4b5ef655f9f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mreconstructed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecompression_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m# Compute reconstruction loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    967\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 968\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-32ca37b35513>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mencoder_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mbin_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mdecoder_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbin_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    967\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 968\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-bf5b66cbd7c5>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhiddens1_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhiddens1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_conv_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhiddens2_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhiddens2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhiddens1_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhiddens3_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhiddens3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhiddens2_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    967\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 968\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-37387a8c864f>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_inputs_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_hidden_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_variable_v2_call\u001b[1;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maggregation\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m       \u001b[0maggregation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariableAggregation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m     return previous_getter(\n\u001b[0m\u001b[0;32m    244\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kws)\u001b[0m\n\u001b[0;32m    234\u001b[0m                         shape=None):\n\u001b[0;32m    235\u001b[0m     \u001b[1;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m     \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_variable_creator_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator_v2\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2632\u001b[0m   \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2634\u001b[1;33m   return resource_variable_ops.ResourceVariable(\n\u001b[0m\u001b[0;32m   2635\u001b[0m       \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2636\u001b[0m       \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    261\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1421\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_proto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1423\u001b[1;33m       self._init_from_args(\n\u001b[0m\u001b[0;32m   1424\u001b[0m           \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[0;32m   1575\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1576\u001b[0m             \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1577\u001b[1;33m           handle = eager_safe_variable_handle(\n\u001b[0m\u001b[0;32m   1578\u001b[0m               \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1579\u001b[0m               \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36meager_safe_variable_handle\u001b[1;34m(initial_value, shape, shared_name, name, graph_mode)\u001b[0m\n\u001b[0;32m    240\u001b[0m   \"\"\"\n\u001b[0;32m    241\u001b[0m   \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m   return _variable_handle_from_shape_and_dtype(\n\u001b[0m\u001b[0;32m    243\u001b[0m       shape, dtype, shared_name, name, graph_mode, initial_value)\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_variable_handle_from_shape_and_dtype\u001b[1;34m(shape, dtype, shared_name, name, graph_mode, initial_value)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;31m# support string tensors, we encode the assertion string in the Op name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     gen_logging_ops._assert(  # pylint: disable=protected-access\n\u001b[1;32m--> 175\u001b[1;33m         math_ops.logical_not(exists), [exists], name=\"EagerVariableNameReuse\")\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[0mhandle_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcpp_shape_inference_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCppShapeInferenceResult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHandleData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mlogical_not\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m   5408\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5409\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5410\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   5411\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"LogicalNot\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5412\u001b[0m         tld.op_callbacks, x)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "decompression_model = DecompressionNetwork(batch_size)\n",
    "mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "loss_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.9, epsilon=1e-06, amsgrad=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print(\"Start of epoch %d\" % (epoch,))\n",
    "    \n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, x_batch_train in enumerate(train_dataset):\n",
    "        \n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            reconstructed = decompression_model(x_batch_train)\n",
    "            \n",
    "            # Compute reconstruction loss\n",
    "            loss = mse_loss_fn(x_batch_train, reconstructed)\n",
    "            loss += sum(decompression_model.losses)\n",
    "        \n",
    "        grads = tape.gradient(loss, decompression_model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, decompression_model.trainable_weights))\n",
    "\n",
    "        loss_metric(loss)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(\"step %d: mean loss = %.4f\" % (step, loss_metric.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-6)\n",
    "\n",
    "decompression_model.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
    "decompression_model.fit(train_images, train_images, epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.9, epsilon=1e-06, amsgrad=True)\n",
    "\n",
    "def SSIMLoss(y_true, y_pred):\n",
    "    return tf.math.square(1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 2.0)))\n",
    "\n",
    "model.compile(optimizer=opt, loss=SSIMLoss, metrics=[SSIMLoss])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(train_images, train_images, batch_size=batch_size, epochs=20, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Stuff that Might be Useful Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCompressionModel(tf.keras.Model):\n",
    "    def __init__(self, input_shape=(32,32,3), batch_size=64, num_iterations=1):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_iterations = num_iterations\n",
    "        self.model_input_shape = input_shape\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.input_layer = InputLayer(input_shape=input_shape)\n",
    "        self.encoder = Encoder(batch_size)\n",
    "        self.binarizer = Binarizer()\n",
    "        self.decoder = Decoder(batch_size)\n",
    "        \n",
    "    def model(self):\n",
    "        x = Input(shape=self.model_input_shape)\n",
    "        return tf.keras.models.Model(inputs=[self.batch_size] + [x], outputs=self.call(x))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        for iteration in range(self.num_iterations):\n",
    "            \n",
    "            input_layer_output = self.input_layer(inputs)\n",
    "            encoder_output = self.encoder(input_layer_output)\n",
    "            binarizer_output = self.binarizer(encoder_output)\n",
    "            decoder_output = self.decoder(binarizer_output)\n",
    "            \n",
    "            inputs = decoder_output\n",
    "        \n",
    "        self.model_output = decoder_output\n",
    "        \n",
    "        return self.model_output\n",
    "    \n",
    "def get_model():\n",
    "    return RNNCompressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
