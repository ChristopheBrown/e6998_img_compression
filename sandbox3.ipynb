{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "import tensorflow_datasets as tdfs\n",
    "import matplotlib.pyplot as plt\n",
    "from rnnconv import RnnConv\n",
    "\n",
    "print(tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 32, 32, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "(train_images2, train_labels2), (test_images2, test_labels2) = datasets.cifar100.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "train_images2, test_iamges2 = train_images2 / 255.0, test_images2 / 255.0\n",
    "\n",
    "\n",
    "train_images = np.concatenate((train_images, train_images2) ,axis=0)\n",
    "test_images = np.concatenate((test_images, test_images2), axis=0)\n",
    "\n",
    "train_labels = np.concatenate((train_labels, train_labels2), axis=0)# Data Augmentation\n",
    "\n",
    "rot90 = np.rot90(train_images,axes=(1,2))\n",
    "rot180 = np.rot90(train_images,k=2,axes=(1,2))\n",
    "rot270 = np.rot90(train_images,k=3,axes=(1,2))\n",
    "\n",
    "train_images_pro = np.concatenate((train_images, rot90) ,axis=0)\n",
    "train_images_pro.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_loss(y_true, y_pred):\n",
    "    B = batch_size\n",
    "    s = B * H * W * C\n",
    "    n = iterations\n",
    "    beta = 1 / (s * n)\n",
    "    \n",
    "    summation = tf.math.reduce_sum(tf.math.abs(tf.math.subtract(y_true, y_pred)), [0,1,2,3])\n",
    "    return beta * summation\n",
    "\n",
    "def SSIMLoss(y_true, y_pred):\n",
    "    return tf.math.square(1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 2.0)))\n",
    "\n",
    "def PSNRLoss(y_true, y_pred,max_val=1.0):\n",
    "    return tf.image.psnr(y_true, y_pred, max_val=max_val)\n",
    "\n",
    "def SSIM_res_loss(y_true, y_pred):\n",
    "    return SSIMLoss(y_true, y_pred) + residual_loss(y_true, y_pred)\n",
    "\n",
    "def test_model(model, test_images, indexes=np.arange(5)):\n",
    "    img_preds = model.predict(test_images[indexes])\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in indexes:\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(test_images[i], cmap=plt.cm.binary)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in indexes:\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(img_preds[i], cmap=plt.cm.binary)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_metric(model, metric='val_SSIMLoss'):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(model.history[metric])\n",
    "\n",
    "def save_model(model, path):\n",
    "    model.save(path)\n",
    "    print(f'Model saved to: {path}.')\n",
    "    \n",
    "def load_model(path, custom_objects):\n",
    "    '''\n",
    "    path is the directory containing a \"saved_model.pb\" - E.g. path=models/new_model\"\n",
    "    Custom objects must be any user-defined loss functions. E.g. {'SSIMLoss': SSIMLoss, 'PSNRLoss': PSNRLoss, 'residual_loss': residual_loss}\n",
    "    '''\n",
    "    return tf.keras.models.load_model(path, custom_objects=custom_objects)\n",
    "\n",
    "def save_history(history, path):\n",
    "\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "    # save to csv: \n",
    "    hist_csv_file = f'{path}/history.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(iterations):\n",
    "    \n",
    "    model = tf.keras.Sequential() \n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        model.add(layers.Conv2D(filters=64, kernel_size=3, input_shape=(32, 32, 3), strides = (2, 2), padding='same', data_format='channels_last'))\n",
    "        model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "        model.add(layers.Lambda(lambda x: tf.expand_dims(x,axis=1)))\n",
    "        model.add(layers.ConvLSTM2D(filters=256, kernel_size=3, strides=(2, 2),   padding='same', data_format='channels_last'))\n",
    "        model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "        model.add(layers.Lambda(lambda x: tf.expand_dims(x,axis=1)))\n",
    "        model.add(layers.ConvLSTM2D(filters=512, kernel_size=3, strides=(2, 2),   padding='same', data_format='channels_last'))\n",
    "        model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "        model.add(layers.Lambda(lambda x: tf.expand_dims(x,axis=1)))\n",
    "        model.add(layers.ConvLSTM2D(filters=512, kernel_size=3, strides=(2, 2),   padding='same', data_format='channels_last'))\n",
    "        model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "        model.add(layers.Conv2D(filters=32, kernel_size=1,  strides = (1,1), padding='same', data_format='channels_last'))\n",
    "        model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "        model.add(layers.Conv2D(filters=512, kernel_size=1,  strides = (1,1), padding='same', data_format='channels_last'))\n",
    "        model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "        model.add(layers.Lambda(lambda x: tf.expand_dims(x,axis=1)))\n",
    "        model.add(layers.ConvLSTM2D(filters=512, kernel_size=2, strides=(1, 1), padding='same', data_format='channels_last'))\n",
    "        model.add(LeakyReLU(alpha=0.01))\n",
    "        model.add(layers.Lambda(lambda x:tf.nn.depth_to_space(x,2,data_format='NHWC')))\n",
    "\n",
    "        model.add(layers.Lambda(lambda x: tf.expand_dims(x,axis=1)))\n",
    "        model.add(layers.ConvLSTM2D(filters=512, kernel_size=3, strides=(1, 1), padding='same', data_format='channels_last'))\n",
    "        model.add(LeakyReLU(alpha=0.01))\n",
    "        model.add(layers.Lambda(lambda x:tf.nn.depth_to_space(x,2,data_format='NHWC')))\n",
    "\n",
    "\n",
    "        model.add(layers.Lambda(lambda x: tf.expand_dims(x,axis=1)))\n",
    "        model.add(layers.ConvLSTM2D(filters=256, kernel_size=3, strides=(1, 1), padding='same', data_format='channels_last'))\n",
    "        model.add(LeakyReLU(alpha=0.01))\n",
    "        model.add(layers.Lambda(lambda x:tf.nn.depth_to_space(x,2,data_format='NHWC')))\n",
    "\n",
    "        model.add(layers.Lambda(lambda x: tf.expand_dims(x,axis=1)))\n",
    "        model.add(layers.ConvLSTM2D(filters=128, kernel_size=3, strides=(1, 1), padding='same', data_format='channels_last'))\n",
    "        model.add(LeakyReLU(alpha=0.01))\n",
    "        model.add(layers.Lambda(lambda x:tf.nn.depth_to_space(x,2,data_format='NHWC')))\n",
    "\n",
    "        model.add(layers.Conv2D(filters=3, kernel_size=1, strides = (1,1), padding='same', data_format='channels_last'))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate, \n",
    "                                   beta_1=0.9, beta_2=0.999, \n",
    "                                   epsilon=1e-06, amsgrad=True)\n",
    "    \n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=SSIM_res_loss, \n",
    "                  metrics=[SSIMLoss, PSNRLoss, residual_loss, \"mae\", \"acc\"])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5\n",
    "iterations = 1\n",
    "batch_size = 512\n",
    "H = train_images.shape[1]\n",
    "W = train_images.shape[2]\n",
    "C = train_images.shape[3]\n",
    "initial_learning_rate = 0.01\n",
    "validation_split=0.05\n",
    "\n",
    "model = get_model(iterations=1)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 10s 996ms/step - loss: 1.1108 - SSIMLoss: 0.7344 - PSNRLoss: 8.0892 - residual_loss: 0.3407 - mae: 0.3672 - acc: 0.2458 - val_loss: 0.6760 - val_SSIMLoss: 0.5612 - val_PSNRLoss: 11.4459 - val_residual_loss: 0.1148 - val_mae: 0.2352 - val_acc: 0.2331\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 7s 705ms/step - loss: 0.7470 - SSIMLoss: 0.5335 - PSNRLoss: 12.1136 - residual_loss: 0.2032 - mae: 0.2190 - acc: 0.3652 - val_loss: 0.6172 - val_SSIMLoss: 0.5132 - val_PSNRLoss: 12.3559 - val_residual_loss: 0.1040 - val_mae: 0.2130 - val_acc: 0.5028\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 7s 709ms/step - loss: 0.7233 - SSIMLoss: 0.5173 - PSNRLoss: 12.3952 - residual_loss: 0.1968 - mae: 0.2122 - acc: 0.5160 - val_loss: 0.6133 - val_SSIMLoss: 0.5120 - val_PSNRLoss: 12.6361 - val_residual_loss: 0.1013 - val_mae: 0.2075 - val_acc: 0.5028\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 7s 710ms/step - loss: 0.7185 - SSIMLoss: 0.5124 - PSNRLoss: 12.5509 - residual_loss: 0.1942 - mae: 0.2093 - acc: 0.3921 - val_loss: 0.6113 - val_SSIMLoss: 0.5102 - val_PSNRLoss: 12.6558 - val_residual_loss: 0.1012 - val_mae: 0.2072 - val_acc: 0.2331\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 7s 714ms/step - loss: 0.7170 - SSIMLoss: 0.5113 - PSNRLoss: 12.5597 - residual_loss: 0.1940 - mae: 0.2091 - acc: 0.3167 - val_loss: 0.6092 - val_SSIMLoss: 0.5083 - val_PSNRLoss: 12.6847 - val_residual_loss: 0.1008 - val_mae: 0.2065 - val_acc: 0.5028\n"
     ]
    }
   ],
   "source": [
    "# Include the epoch in the file name (uses `str.format`)\n",
    "checkpoint_path = \"weights/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=1*batch_size)\n",
    "\n",
    "decay = initial_learning_rate / epochs\n",
    "def lr_time_based_decay(epoch, lr):\n",
    "    return lr * 1 / (1 + decay * epoch)\n",
    "\n",
    "\n",
    "model_history = model.fit(train_images[0:5000], train_images[0:5000], \n",
    "                          batch_size=batch_size, \n",
    "                          epochs=epochs, \n",
    "                          validation_split=validation_split, \n",
    "                          callbacks=[cp_callback])\n",
    "\n",
    "\n",
    "\n",
    "# # Save the weights using the `checkpoint_path` format\n",
    "# model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: models/new_model/assets\n",
      "Model saved to: models/new_model.\n"
     ]
    }
   ],
   "source": [
    "path = 'models/new_model'\n",
    "save_model(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {'SSIMLoss': SSIMLoss, 'PSNRLoss': PSNRLoss, 'residual_loss': residual_loss, 'SSIM_res_loss': SSIM_res_loss}\n",
    "loaded_model = load_model(path, custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(loaded_model, test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
