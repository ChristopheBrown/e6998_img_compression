{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, logging\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Input\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "# import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "logging.disable(logging.WARNING) \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.3.1\n",
      "Is GPU available? [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Eager execution on? True\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n",
    "print(\"Is GPU available? {}\".format(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Eager execution on? {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Layer Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is to perform the rnn_conv operation that makes up the building block of the encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_conv_channels = 32\n",
    "\n",
    "D_conv1_channels = 512\n",
    "D_rnn1_channels = 512\n",
    "D_rnn2_channels = 512\n",
    "D_rnn3_channels = 256\n",
    "D_rnn4_channels = 128\n",
    "D_conv2_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.normal(size=(128,32,32,3))\n",
    "ENCODER_DIM = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Class Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnConv(Layer):\n",
    "    \n",
    "    def __init__(self, filters, kernel_size, strides, index, batch_size):\n",
    "        \n",
    "        super(RnnConv, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.index = index        \n",
    "        self.hidden, self.cell = self.init_hiddens(filters)\n",
    "        \n",
    "        self.conv_inputs_layers = Conv2D(filters=filters, kernel_size=4*kernel_size, strides=strides, padding=\"same\", trainable=True)\n",
    "        self.conv_hidden_layers = Conv2D(filters=filters, kernel_size=4*kernel_size, padding=\"same\", trainable=True)\n",
    "        \n",
    "        self.in_gate = Dense(filters, activation=\"sigmoid\", dtype='float32', trainable=True)\n",
    "        self.f_gate = Dense(filters, activation=\"sigmoid\", dtype='float32', trainable=True)\n",
    "        self.out_gate = Dense(filters, activation=\"sigmoid\", dtype='float32', trainable=True)\n",
    "        self.c_gate = Dense(filters, activation=\"tanh\", dtype='float32', trainable=True)\n",
    "        \n",
    "        self.hidden_weight = Dense(1, activation=\"tanh\", dtype='float32', trainable=True)\n",
    "\n",
    "    def init_hiddens(self, num_filters):\n",
    "\n",
    "        h_w_scale_factor = 2**(self.index+1)\n",
    "        h_w = int(32 // h_w_scale_factor) #32 is the input dims, decreasing by factor of 2 for each layer\n",
    "\n",
    "        shape = [self.batch_size] + [h_w, h_w] + [num_filters]\n",
    "        hidden = tf.zeros(shape, dtype='float32')\n",
    "        cell = tf.zeros(shape, dtype='float32')\n",
    "\n",
    "        return (hidden, cell)\n",
    "    \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        self.batch_size = inputs.shape[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_inputs = self.conv_inputs_layers(tf.Variable(inputs))\n",
    "        self.conv_hidden = self.conv_hidden_layers(self.hidden)\n",
    "\n",
    "        in_gate, f_gate, out_gate, c_gate = tf.split(self.conv_inputs + self.conv_hidden, 4, axis=-1)\n",
    "         \n",
    "        in_gate_output = self.in_gate(in_gate)\n",
    "        f_gate_output = self.f_gate(f_gate)\n",
    "        out_gate_output = self.out_gate(out_gate)\n",
    "        c_gate_output = self.c_gate(c_gate)\n",
    "        \n",
    "        new_cell = tf.math.add(tf.multiply(f_gate_output, self.cell), tf.multiply(in_gate_output, c_gate_output))\n",
    "        new_hidden = tf.multiply(out_gate_output, self.hidden_weight(new_cell))\n",
    "        \n",
    "        for old_state, new_state in zip(tf.nest.flatten(self.cell), tf.nest.flatten(new_cell)):\n",
    "            old_state = new_state\n",
    "            \n",
    "        for old_hidden, new_hidden in zip(tf.nest.flatten(self.hidden), tf.nest.flatten(new_hidden)):\n",
    "            old_hidden = new_hidden        \n",
    "        \n",
    "        # self.cell = self.new_cell # should this update the state of the LSTM cell in this layer (and not propagate forward)\n",
    "        # self.hidden = self.new_hidden\n",
    "        \n",
    "        return (self.hidden, self.cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Layer):\n",
    "    \n",
    "    def __init__(self, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        write defintions of stuff here\n",
    "        \"\"\"\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # self.batch_size, self.height, self.width, self.channels = images.shape\n",
    "        self.E_conv_channels = 64\n",
    "        self.E_rnn1_channels = 256\n",
    "        self.E_rnn2_channels = 512\n",
    "        self.E_rnn3_channels = 512\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.input_conv = Conv2D(input_shape=(32,32,3), filters=self.E_conv_channels, kernel_size=3, activation = \"relu\", strides = (2,2), padding='same', dtype='float32', trainable=True)\n",
    "        self.hiddens1 = RnnConv(filters=self.E_rnn1_channels, kernel_size=3, strides=2, index=1, batch_size=self.batch_size)\n",
    "        self.hiddens2 = RnnConv(filters=self.E_rnn2_channels, kernel_size=3, strides=2, index=2, batch_size=self.batch_size)\n",
    "        self.hiddens3 = RnnConv(filters=self.E_rnn3_channels, kernel_size=3, strides=2, index=3, batch_size=self.batch_size)\n",
    "    \n",
    "    \n",
    "    def call(self, inputs):\n",
    "                        \n",
    "        self.input_conv_result = self.input_conv(inputs)\n",
    "                \n",
    "        self.hiddens1_output = self.hiddens1(self.input_conv_result)          \n",
    "        self.hiddens2_output = self.hiddens2(self.hiddens1_output[0])\n",
    "        self.hiddens3_output = self.hiddens3(self.hiddens2_output[0])\n",
    "                \n",
    "        return self.hiddens3_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binarizer(Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Binarizer, self).__init__()\n",
    "        \n",
    "        self.bin_input = Conv2D(input_shape=(2,2,512), filters=32, strides=1, kernel_size=1, activation=tf.nn.tanh, padding=\"same\", trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "    \n",
    "        bin_input_conv = self.bin_input(inputs)\n",
    "        probability = (bin_input_conv + 1) / 2\n",
    "        \n",
    "        # distribution = tfp.distributions.Bernoulli(probs=probability, dtype=tf.float32)\n",
    "        # noise = 2 * distribution.sample() - 1 - bin_input_conv\n",
    "        \n",
    "        bin_output = bin_input_conv # + tf.stop_gradient(noise)\n",
    "                \n",
    "        bits = tf.math.sign(bin_output)\n",
    "        \n",
    "        \n",
    "        return bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Layer):\n",
    "    \n",
    "    def __init__(self, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # self.batch_size, self.height, self.width, self.channels = images.shape\n",
    "        self.D_conv_channels = 512\n",
    "        self.D_rnn1_channels = 512\n",
    "        self.D_rnn2_channels = 256\n",
    "        self.D_rnn3_channels = 256\n",
    "        self.D_rnn4_channels = 128\n",
    "        \n",
    "        self.input_conv = Conv2D(input_shape=(2,2,32), filters=512, strides=1, kernel_size=1, activation=\"relu\", padding=\"same\", dtype='float32', trainable=True)\n",
    "        \n",
    "        self.lambda_layer1 = layers.Lambda(lambda x: tf.nn.depth_to_space(input=x, block_size=2, data_format=\"NHWC\"))\n",
    "        self.lambda_layer2 = layers.Lambda(lambda x: tf.nn.depth_to_space(input=x, block_size=2, data_format=\"NHWC\"))\n",
    "        self.lambda_layer3 = layers.Lambda(lambda x: tf.nn.depth_to_space(input=x, block_size=2, data_format=\"NHWC\"))\n",
    "        self.lambda_layer4 = layers.Lambda(lambda x: tf.nn.depth_to_space(input=x, block_size=2, data_format=\"NHWC\"))\n",
    "        \n",
    "        self.hiddens1 = RnnConv(filters=self.D_rnn1_channels, kernel_size=2, strides=1, index=3, batch_size=self.batch_size)\n",
    "        self.hiddens2 = RnnConv(filters=self.D_rnn2_channels, kernel_size=3, strides=1, index=2, batch_size=self.batch_size)\n",
    "        self.hiddens3 = RnnConv(filters=self.D_rnn3_channels, kernel_size=3, strides=1, index=1, batch_size=self.batch_size)\n",
    "        self.hiddens4 = RnnConv(filters=self.D_rnn4_channels, kernel_size=3, strides=1, index=0, batch_size=self.batch_size)\n",
    "                \n",
    "        self.output_conv = Conv2D(filters=3, strides=1, kernel_size=1, activation=\"relu\", padding=\"same\", trainable=True)\n",
    "    \n",
    "    \n",
    "    def call(self, binarizer_output):\n",
    "        \n",
    "        self.input_conv_result = self.input_conv(binarizer_output)\n",
    "                \n",
    "        self.hiddens1_output = self.hiddens1(self.input_conv_result) \n",
    "        self.depth_to_space1 = self.lambda_layer1(self.hiddens1_output[0])\n",
    "        \n",
    "        self.hiddens2_output = self.hiddens2(self.depth_to_space1) \n",
    "        self.depth_to_space2 = self.lambda_layer2(self.hiddens2_output[0])\n",
    "        \n",
    "        self.hiddens3_output = self.hiddens3(self.depth_to_space2) \n",
    "        self.depth_to_space3 = self.lambda_layer3(self.hiddens3_output[0])\n",
    "        \n",
    "        self.hiddens4_output = self.hiddens4(self.depth_to_space3) \n",
    "        self.depth_to_space4 = self.lambda_layer4(self.hiddens4_output[0])\n",
    "        \n",
    "        self.output_conv_results = self.output_conv(self.depth_to_space4)\n",
    "                \n",
    "        return self.output_conv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecompressionNetwork(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, batch_size):\n",
    "        super(DecompressionNetwork, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.encoder = Encoder(self.batch_size)\n",
    "        self.binarizer = Binarizer()\n",
    "        self.decoder = Decoder(self.batch_size)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        encoder_output = self.encoder(inputs)\n",
    "        bin_output = self.binarizer(encoder_output)\n",
    "        decoder_output = self.decoder(bin_output)\n",
    "        \n",
    "        # compute loss\n",
    "        im1 = tf.image.convert_image_dtype(inputs, tf.float32)\n",
    "        im2 = tf.image.convert_image_dtype(decoder_output, tf.float32)\n",
    "        \n",
    "        ssim_loss = tf.reduce_mean(tf.image.ssim(im1, im2, 2.0))\n",
    "        ssim_loss = tf.dtypes.cast(ssim_loss, tf.float32)\n",
    "        self.add_loss(ssim_loss)\n",
    "        \n",
    "        decoder_output = tf.Variable(decoder_output, dtype=tf.float32)\n",
    "        \n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "step 0: mean loss = 0.2855\n",
      "step 100: mean loss = 0.2902\n",
      "step 200: mean loss = 0.2927\n",
      "step 300: mean loss = 0.2921\n",
      "step 400: mean loss = 0.2915\n",
      "step 500: mean loss = 0.2915\n",
      "step 600: mean loss = 0.2909\n",
      "step 700: mean loss = 0.2913\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [16,8,8,256] vs. [64,8,8,256] [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4b5ef655f9f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mreconstructed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecompression_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Compute reconstruction loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-7b2e2ab02a24>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mbin_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a3e342bddf48>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_conv_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens1_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_conv_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens2_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens1_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens3_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens2_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-10c6803ca4db>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_hidden_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0min_gate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_gate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_gate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_gate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_inputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0min_gate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_gate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_gate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1446\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    484\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [16,8,8,256] vs. [64,8,8,256] [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "decompression_model = DecompressionNetwork(batch_size)\n",
    "mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "loss_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.9, epsilon=1e-06, amsgrad=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print(\"Start of epoch %d\" % (epoch,))\n",
    "    \n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, x_batch_train in enumerate(train_dataset):\n",
    "        \n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            reconstructed = decompression_model(x_batch_train)\n",
    "            \n",
    "            # Compute reconstruction loss\n",
    "            loss = mse_loss_fn(x_batch_train, reconstructed)\n",
    "            loss += sum(decompression_model.losses)\n",
    "        \n",
    "        grads = tape.gradient(loss, decompression_model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, decompression_model.trainable_weights))\n",
    "\n",
    "        loss_metric(loss)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(\"step %d: mean loss = %.4f\" % (step, loss_metric.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-6)\n",
    "\n",
    "decompression_model.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
    "decompression_model.fit(train_images, train_images, epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.9, epsilon=1e-06, amsgrad=True)\n",
    "\n",
    "def SSIMLoss(y_true, y_pred):\n",
    "    return tf.math.square(1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 2.0)))\n",
    "\n",
    "model.compile(optimizer=opt, loss=SSIMLoss, metrics=[SSIMLoss])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(train_images, train_images, batch_size=batch_size, epochs=20, validation_split=0.05)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
